version: '3.8'

services:
  redis:
    container_name: redis_container_ya
    image: redis:7-bookworm
    command: redis-server --requirepass ${REDIS_PASSWORD}
    ports:
      - "${REDIS_PORT}:${REDIS_PORT}"
    volumes:
      - redis_data:/data/bookworm/redis
    healthcheck:
      test: [ "CMD", "redis-cli", "-a", "$REDIS_PASSWORD", "ping" ]
      interval: 1s
      timeout: 5s
      retries: 10
    networks:
      - orders_network
    env_file:
      - .env

  elasticsearch:
    container_name: elasticsearch_container_ya
    image: elasticsearch:8.17.4
    ports:
      - "${ELASTICSEARCH_PORT}:${ELASTICSEARCH_PORT}"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
    networks:
      - orders_network
    healthcheck:
      interval: 10s
      retries: 80
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:${ELASTICSEARCH_PORT}/
    env_file:
      - .env

  kafka-connect:
    container_name: kafka-connect_container_ya
    image: confluentinc/cp-kafka-connect:7.4.0
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8083:8083"
    environment:
        CONNECT_BOOTSTRAP_SERVERS: kafka:9092
        CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
        CONNECT_REST_PORT: 8083
        CONNECT_GROUP_ID: compose-connect-group
        CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
        CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
        CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
        CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
        CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
        CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
        CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
        CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
        CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
    volumes:
      - ./connectors/elasticsearch-connector:/tmp/elasticsearch-connector
    networks:
      - orders_network

  zookeeper:
    container_name: zookeeper_container_ya
    image: confluentinc/cp-zookeeper:7.4.0
    ports:
      - "${ZOOKEEPER_CLIENT_PORT}:${ZOOKEEPER_CLIENT_PORT}"
    environment:
      - ZOOKEEPER_CLIENT_PORT=${ZOOKEEPER_CLIENT_PORT}
      - ZOOKEEPER_TICK_TIME=${ZOOKEEPER_TICK_TIME}
    env_file:
      - .env
    networks:
      - orders_network

  kafka:
    container_name: kafka_container_ya
    image: confluentinc/cp-kafka:7.4.0
    ports:
      - "${KAFKA_LISTENER_PLAIN_PORT}:${KAFKA_LISTENER_PLAIN_PORT}"
    environment:
      - KAFKA_BROKER_ID=${KAFKA_BROKER_ID}
      - KAFKA_LISTENER_NAME=${KAFKA_LISTENER_NAME}
      - KAFKA_ZOOKEEPER_CONNECT=${KAFKA_ZOOKEEPER_CONNECT}
      - KAFKA_LISTENER_PLAIN_PORT=${KAFKA_LISTENER_PLAIN_PORT}
      - KAFKA_ADVERTISED_LISTENERS=${KAFKA_ADVERTISED_LISTENERS}
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR}
    healthcheck:
      test: [ "CMD", "kafka-topics", "--bootstrap-server", "localhost:${KAFKA_LISTENER_PLAIN_PORT}", "--list" ]
      interval: 1s
      timeout: 5s
      retries: 10
    depends_on:
      - zookeeper
    env_file:
      - .env
    networks:
      - orders_network

  postgres:
    container_name: postgres_container_ya
    image: postgres:17-bookworm
    environment:
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_PORT=${POSTGRES_PORT}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASS}
      - POSTGRES_DB=${POSTGRES_DB}
    volumes:
      - postgres_data:/data/bookworm/postgres
    ports:
      - "${POSTGRES_PORT}:${POSTGRES_PORT}"
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -d ${POSTGRES_DB} -U ${POSTGRES_USER}"]
      interval: 1s
      timeout: 5s
      retries: 10
    networks:
      - orders_network
    env_file:
      - .env

  nginx:
    container_name: nginx
    image: nginx:1.27
    ports:
      - "80:80"
    volumes:
      - ./nginx:/etc/nginx/conf.d/
    depends_on:
      - orders1
      - orders2
      - orders3
    networks:
      - orders_network

  orders1:
    container_name: orders_container_ya1
    build:
      dockerfile: ./Dockerfile
      context: .
    ports:
      - "8081:8081"
      - "50051:50051"
    environment:
      - GRPC_PORT=${GRPC_PORT}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    networks:
      - orders_network
    env_file:
      - .env

  orders2:
    container_name: orders_container_ya2
    build:
      dockerfile: ./Dockerfile
      context: .
    ports:
      - "50052:50051"
    environment:
      - GRPC_PORT=${GRPC_PORT}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      orders1:
        condition: service_started
    networks:
      - orders_network
    env_file:
      - .env

  orders3:
    container_name: orders_container_ya3
    build:
      dockerfile: ./Dockerfile
      context: .
    ports:
      - "50053:50051"
    environment:
      - GRPC_PORT=${GRPC_PORT}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      orders1:
        condition: service_started
      orders2:
        condition: service_started
    networks:
      - orders_network
    env_file:
      - .env

volumes:
  postgres_data:
  redis_data:
  esdata:
    driver: local

networks:
  orders_network:
    driver: bridge